# Gaussian-Mixture-Model

Expectation Maximization Algorithm

Gaussian Mixture Models (GMM) are effective for multi model density representation. In this experiment GMM Parameters are estimated using Expectation Maximization(EM) algorithm results are shown for two datasets. The GMM algorithm and plotting functions are given in python code.

Following are the requirements to run this code: Python 3.7.2

## 1.Reference
- Bishop, Christopher M. Pattern recognition and machine learning. Vol. 4. No. 4. New York: springer, 2006. Chapter 9
- Geometry & Recognition :: Gaussian Mixture Model & K-means

## 2.GMM Density Estimation of Iris Dataset

First for each feature in Iris dataset, Gaussian mixture models (GMM) parameters are estimated by using two or three GMM components. The Number of components in GMM are determined by visualizing respective feature's histogram. usually for this dataset features, two components were enough.

## 3.Gentle Introduction
![image](https://user-images.githubusercontent.com/53164959/83671807-3eb5a280-a610-11ea-9663-c3110bb36adc.png)

## 4.EM algorithm
![image](https://user-images.githubusercontent.com/53164959/83671905-63aa1580-a610-11ea-85f3-b560e154ee7e.png)

![image](https://user-images.githubusercontent.com/53164959/83671970-7c1a3000-a610-11ea-92e5-042ac69f5f32.png)
                              <slides from il-chul Moon,Department of System Engineering,KAIST>
## 5. Visualization

![image](https://user-images.githubusercontent.com/53164959/83673010-26df1e00-a612-11ea-9c7e-0ea568546793.png)
